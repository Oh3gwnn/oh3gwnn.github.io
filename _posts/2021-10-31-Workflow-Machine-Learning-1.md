---
title:  "머신러닝 워크플로우(The universal workflow of machine learning) - 1"
excerpt: "머신러닝 워크플로우와 작업 정의(Define the task), 모델 개발(Develop a model)"

categories:
 - AI
tags:
 - [python, machine learning]

toc: true
toc_sticky: true

date: 2021-10-31
last_modified_at: 2021-10-31
---

#### **서론: 머신러닝의 윤리에 대해**

`머신러닝을 배울 때, 시작할 레이블이 지정된 데이터 세트가 있고 모델 훈련을 시작하는 데, 실제로는 문제에서 시작하는 경우가 기본적입니다. 책에서는 사진 검색엔진, 텍스트 스팸, 카드 감지 등 여러 가지 분야에서 머신러닝이 활용되고 있습니다.`

`또한, 윤리 관련해서 '얼굴 사진으로 신뢰도를 평가하는 AI'와 같은 타당성이 있는지 의심되는 프로젝트도 진행할 수 있는데, 왜 신뢰성이 누군가의 얼굴에 반영되는지 명확하지 않을뿐더러 이런 작업은 모든 종류의 윤리적인 문제를 제기합니다.`

`어떤 특정 인물이 이 사람은 신뢰할 수 없다고 말하는 것보다 AI가 이 사람은 신뢰할 수 없다하는 것이 더 비중과 객관성을 띄는 것으로 보이기 때문에 우리가 제작하는 모델은 사람 판단의 부정적인 면을 제외하고 동작시키고, 부정적인 영향을 끼칠 수 있습니다.`

`결론적으론, 기술은 절대 중립일 수 없고 우리가 제작한 모델이 세상에 도덕적인 영향을 끼칠 수 있기 때문에 항상 제작되는 모델, 기술 등에서 고민하고 주의하여 훈련, 제작에 힘써야 합니다.`

---

## **1. 머신러닝의 일반적인 워크플로우(The universal workflow of machine learning)**

머신러닝의 워크플로우는 보편적으로 세 부분으로 구성됩니다.

 - **작업 정의(Define the task)**: 기계 학습 문제를 구성하는 단계 - 고객의 질문의 근저에 있는 문제 도메인과 비즈니스 로직을 이해합니다. 데이터 셋을 수집하여 데이터가 무엇을 나타내는지 이해하고 작업 성공을 어떻게 측정할 것인지 선택합니다.

 - **모델 개발(Develop a model)**: 작업 모델 개발 단계 - 머신러닝 모델에서 데이터를 처리할 수 있도록 준비하고, 모델 평가 프로토콜과 단순한 베이스라인을 선택하여, 지나치게 적합한 일반화 능력을 가진 최초의 모델을 훈련하고, 가능한 최고의 일반화 성능을 달성할 때까지 모델을 정규화하고 조정합니다.

 - **모델 도입(Deploy the model)**: 운영 시 모델을 배치하고 유지하는 단계 - 작업 내용을 관계자에게 제시하고 모델을 웹 서버, 모바일 애플리케이션, 웹 페이지 또는 임베디드 디바이스에 전송하여 모델의 야외 퍼포먼스를 감시하고 차세대 모델 구축에 필요한 데이터 수집을 시작합니다.

---

### **1.1. 작업 정의(Define the task)**

자신이 하고 있는 작업의 문제를 깊이 이해하지 않으면 좋은 작업을 할 수 없다. 고객들은 왜 이 특정한 문제를 해결하려고 하고, 고객은 솔루션에서 어떤 가치를 얻을지, 제작 모델은 어떻게 사용되며, 비즈니스 과정에 얼마나 적합한지 등의 고민이 있을 수 있습니다. 머신러닝 문제를 구성하려면 일반적으로 이해 관계자(stakeholders)와 상세한 논의가 필요합니다.

#### **1.1.1. 문제 구성(Frame the problem)**

 - 데이터 가용성(data availability)이 제한요인이 된다.
입력 데이터나 무엇을 예측하려는 것인지에 따라서 대부분 새로운 데이터셋을 가져오고, 스스로 특성을 붙여야 합니다.

 - 어떤 유형의 기계 학습 작업을 선택할 것인지 고민해야 한다.
예를 들면, 사진 검색은 멀티클래스, 멀티라벨 분류, 스팸 탐지는 이진분류 작업이다. 데이터의 종류나 어떤 문제냐에 따라 선택해야 할 작업이 다릅니다.

 - 기존 솔루션이 무엇인지 생각해야 한다.
사람의 수작업으로 진행되는 공정과정을 보면 어떤 시스템이 이미 도입되었고, 어떤 기능을 하고 있는지 이해해야 합니다.

 - 처리해야 할 특정한 제약이 있는지 찾아야 한다.
예를 들어 스팸 검출 시스템을 구축하고 있는 애플리케이션은 end-to-end에서 암호화 되어있기 때문에, 외부 데이터 세트로 훈련해야 합니다. 즉, 하고자 하는 작업의 전체적인 맥락을 파악해야 합니다.

이렇게 조사가 완료되면 입력내용(input), 목표(target) 및 문제가 어떤 종류의 머신러닝(machine learning) 작업에 매핑(mapping)되는지 파악해야 합니다.

단, 이 단계에서 작성한 가설에 주의해야 합니다.

 - 입력을 고려하여 목표를 예측할 수 있다고 가정한다.

 - 사용가능한(또는 바로 수집하는) 데이터는 입력과 목표의 관계를 학습하기에 충분한 정보라고 가정한다.

실제 모델이 만들어질 때까지 위 내용은 단순한 가설일 뿐, 검증(validated) 또는 무효화(invalidated)를 작업을 기다리고 있습니다. 머신 러닝으로 모든 문제를 해결할 수 있는 것은 아닙니다. 입력 값 X와 목표인 Y를 조립한다고 해서 X가 Y를 예측하기에 충분한 정보를 포함하고 있는 것은 아닙니다.

#### **1.1.2. 데이터 세트 수집(Collect a dataset)**

작업을 이해하고, 입력과 목표가 무엇인지를 이해한다면, 머신러닝 프로젝트에서 가장 어렵고 시간‧비용이 많이 드는 데이터 수집의 단계로 넘어갑니다. 예를 들면, 사진 검색 엔진 프로젝트에서는 먼저 분류 라벨 세트를 선택해야 합니다. 10,000의 일반적인 이미지 카테고리로 설정합니다. 다음으로 사용자가 업로드한 수십만의 이미지에 이 세트의 라벨을 수동으로 태그 붙여야 합니다.

모델의 일반화 능력은 훈련된 데이터의 특성, 즉 데이터 포인트 수, 레이블의 신뢰성, 기능의 품질에서 나옵니다. 훌륭한 데이터 셋은 주의해서 투자할 만한 자산입니다. 프로젝트가 50시간 더 소요될 경우 모델링 개선점을 찾을 것이 아니라 더 많은 데이터를 수집하는 것이 가장 효과적인 방법일 수 있습니다.

알고리즘보다 데이터가 중요하다는 점은 구글 연구자에 의한 2009년 논문 "The Unreasonable Effectiveness of Data“에서부터 유명해졌습니다. 이는 딥러닝 학습이 유명해지기 전의 일이지만 놀랍게도 딥러닝의 대두는 데이터의 중요성을 더 키웠습니다.

지도학습을 하는 경우 입력(이미지 등)을 수집하면 그 입력(이미지 태그 등)에 대한 주석이 필요합니다. 이것은 예측할 수 있는 것처럼 모델을 훈련하는 목표물입니다.

주석은 음악 추천 작업이나 선택 예측 작업의 경우 자동으로 수집되지만, 종종 수작업으로 데이터에 주석을 달아주어야 합니다. 이 과정은 노동력이 많이 드는 과정(labor-heavy process)입니다.

**데이터-주석 인프라 투자(Investing in data-annotation infrastructure)**

데이터 주석 프로세스에 의해 목표의 품질이 결정되고 모델의 품질이 결정됩니다. 사용 가능한 옵션을 충분히 검토해야합니다.
 - 데이터에 직접 주석을 달아야 하는지

 - 라벨 수집을 위해 메카니컬 터크(Mechanical Turk: 컴퓨터로 대응할 수 없지만 인간의 지능을 활용하면 쉬운 과업같은 느낌)와 같은 클라우드 소싱 플랫폼(crowdsourcing platform)을 사용해야 하는지

 - 데이터 라벨 전문 회사의 서비스를 이용해야 하는지

아웃소싱을 통해 시간과 비용을 절약할 수 있지만 본인이 관리할 수는 없게 됩니다. 메카니컬 터크(Mechanical Turk)를 사용하는 것은 저렴하게 확장할 수 있지만, 주석은 꽤 시끄러울 수 있습니다.

최적의 옵션을 선택하려면, 다음 제약을 고려해야 합니다.

 - 데이터 라벨기가 대상 분야에 대해 전문성을 띄어야 하는지, 고양이와 개의 이미지 분류 문제의 라벨은 누구라도 선택할 수 있지만 견종 분류 작업의 라벨은 전문 지식이 필요하다. 또한, 골절의 CT 검사에서 주석을 달기 위해서는 의학 학위가 필요합니다.

 - 데이터에 주석을 달기 위해 전문 지식이 필요한 경우 사람이 주석을 달기 위해 훈련시킬 수 있는지, 그렇지 않으면 어떻게 관련 전문가와 접촉할 수 있는지

 - 전문가들이 주석을 다는 것을 이해할 수 있는지, 그렇지 않으면 데이터 셋을 블랙박스(결과는 원하는 대로 도출하지만, 근거를 알 수 없는 것)로 취급해야 하며 수동기능 엔지니어링(manual feature engineering)을 수행할 수 없습니다. 이는 중요하진 않지만 제한적일 수 있습니다.

 **비대표적 데이터 주의(Beware of non-representative data)**

머신 러닝 모델은, 이전에 본 것과 같은 입력 만 이해할 수 있다. 교육(Train) 데이터는 생산(Production) 데이터를 대표하지 않기 때문에 트레이닝에 사용하는 데이터가 실제 데이터를 대표하는 것이 중요합니다. 이 문제는 모든 데이터 수집 작업의 기초가 됩니다.

가능하면 모델이 사용될 환경에서 직접 데이터를 수집합니다. 영화 감상 분류 모델은 Yelp 레스토랑 리뷰나 Twitter 상태 업데이트가 아닌 새로운 IMDB(인터넷 영화 데이터베이스) 리뷰에 사용되어야 합니다. 생산 데이터에 대한 훈련이 가능하지 않다면, 훈련 데이터와 생산 데이터가 어떻게 다른지 완전히 이해하고 이러한 차이를 적극적으로 수정해야 합니다.

주의해야 할 관련현상은 개념 드리프트(Conceept drift: 시간이 지남에 따라 모델링 대상의 통계적 특성이 바뀌는 현상)입니다. 거의 모든 현실적인 문제, 특히 사용자가 생성한 데이터를 다루는 문제로 개념의 변화에 직면하게 되면 생산 데이터의 특성이 시간과 함께 변화하면서 모델 정확도가 서서히 저하될 때 발생한다. 개념 드리프트를 처리하려면 지속적인 데이터 수집, 주석, 모델 재훈련이 필요하다.

머신러닝은 훈련 데이터에 포함된 패턴을 기억하기 위해서만 사용될 수 있다는 점에 유의해야 합니다. 전에 본 것밖에 인식하지 못하기 때문에, 과거의 데이터를 바탕으로 훈련된 머신러닝을 사용하여 미래를 예측하는 것은 미래가 과거와 같이 행동할 것이라고 가정하는 것입니다.


**참고: 샘플링 편향의 문제(SAMPLING BIAS)**

`비대표적 데이터의 내재적이고 일반적인 케이스는 샘플링 편향이다. 샘플링 편향은 데이터 수집 프로세스가 예측하고자 하는 것과 상호작용하여 편향된 측정이 이루어질 때 발생합니다. 예를 들자면 선거 전, 여론 조사를 특정 지역, 특정 나이만 조사한다면, 당연히 편향된 측정이 이루어질 수밖에 없습니다.`

